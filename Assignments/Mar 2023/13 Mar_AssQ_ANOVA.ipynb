{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6fecd3f1-a3dc-4dcf-bb8c-37cbd1385713",
   "metadata": {},
   "source": [
    "## Explain the assumptions required to use ANOVA and provide examples of violations that could impact the validity of the results.\r\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bbbadb8-ff8f-42cd-be91-4cdb159d755e",
   "metadata": {},
   "source": [
    "To use the ANOVA test we made the following assumptions:\r\n",
    "\r\n",
    "The residuals are normally distributed\r\n",
    "\r\n",
    "Group populations have a common variance\r\n",
    "  \r\n",
    "All samples are drawn independently of each other\r\n",
    "  \r\n",
    "Within each sample, the observations are sampled randomly and independently of each other\r\n",
    "  \r\n",
    "Factor effects are additiveditive"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8d86839-64cd-43d2-acc3-dbddbefd6f2d",
   "metadata": {},
   "source": [
    "## Q2. What are the three types of ANOVA, and in what situations would each be used?\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5256fff-fbbe-41e1-b4f2-03ae0f039953",
   "metadata": {},
   "source": [
    "Types: 1. One Way ANOVA, 2. Two Way ANOVA, 3. N Way ANOVA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec0db96d-6545-4973-b2aa-96241a443e19",
   "metadata": {},
   "source": [
    "**One-Way ANOVA**:\r\n",
    "One-Way ANOVA is a statistical method used when we’re looking at the impact of one single factor on a particular outcome. For instance, if we want to explore how IQ scores vary by country, that’s where One-Way ANOVA comes into play\n",
    "\n",
    "**Two-Way ANOVA**:\r\n",
    "Moving a step further, Two-Way ANOVA, also known as factorial ANOVA, allows us to examine the effect of two different factors on an outcome simultaneously. Building on our previous example, we could look at how both country and gender influence IQ scores\n",
    "\n",
    "**N-Way ANOVA**:\n",
    "\r\n",
    "When researchers have more than two factors to consider, they turn to N-Way ANOVA, where “n” represents the number of independent variables in the analysis. This could mean examining how IQ scores are influenced by a combination of factors like country, gender, age group, and ethnicity all at once. N-Way ANOVA allows for a comprehensive analysis of how these multiple factors interact with each other and their combined effect on the dependent variable, providing a deeper understanding of the dynamics at play..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfd8c255-c881-43b3-92ee-c9c917abddb9",
   "metadata": {},
   "source": [
    "## Q3. What is the partitioning of variance in ANOVA, and why is it important to understand this concept?\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "803d9d3d-0972-457d-bf0a-65129e48dc98",
   "metadata": {},
   "source": [
    "**What is the partitioning of variance in ANOVA**:\n",
    "\n",
    "The act of partitioning, or splitting up, is the core idea of ANOVA. To use the house analogy. Our total sums of squares (SS Total) is our big empty house. We want to split it up into little rooms. Before we partitioned SS Total using this formula:\n",
    "\n",
    "SSTOTAL=SSEffect+SSError\n",
    " \n",
    "Remember, the  SSEffect was the variance we could attribute to the means of the different groups, and  SSError was the leftover variance that we couldn’t explain. SSEffect and SSError are the partitions of  SSTOTAL, they are the little rooms.\n",
    "\n",
    "Link: https://stats.libretexts.org/Bookshelves/Applied_Statistics/Answering_Questions_with_Data_-__Introductory_Statistics_for_Psychology_Students_(Crump)/08%3A_Repeated_Measures_ANOVA/8.02%3A_Partioning_the_Sums_of_Squares"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9b8bf80-0f14-48a7-839f-d48f4f19d61e",
   "metadata": {},
   "source": [
    "**Why Partitioning of Variance is Important in ANOVA**:\n",
    "\n",
    "By partitioning total variance into components, ANOVA unravels relationships between variables and identifies true sources of variation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b055afb-1fdc-4c6e-b726-9efcd1306f6b",
   "metadata": {},
   "source": [
    "## Q4. How would you calculate the total sum of squares (SST), explained sum of squares (SSE), and residual sum of squares (SSR) in a one-way ANOVA using Python?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f3545401-33de-4fcf-98ea-10dd2810e80b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hours</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   hours  score\n",
       "0      1     68\n",
       "1      1     76\n",
       "2      1     74\n",
       "3      2     80\n",
       "4      2     76"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "#create pandas DataFrame\n",
    "df = pd.DataFrame({'hours': [1, 1, 1, 2, 2, 2, 2, 2, 3, 3,\n",
    "                             3, 4, 4, 4, 5, 5, 6, 7, 7, 8],\n",
    "                   'score': [68, 76, 74, 80, 76, 78, 81, 84, 86, 83,\n",
    "                             88, 85, 89, 94, 93, 94, 96, 89, 92, 97]})\n",
    "\n",
    "#view first five rows of DataFrame\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "256d0b23-3930-47a5-b0f4-3168df304962",
   "metadata": {},
   "source": [
    "## Next, we’ll use the OLS() function from the statsmodels library to fit a simple linear regression model using score as the response variable and hours as the predictor variable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "459f06f7-e844-4358-a60c-89d4c068a7ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "\n",
    "#define response variable\n",
    "y = df['score']\n",
    "\n",
    "#define predictor variable\n",
    "x = df[['hours']]\n",
    "\n",
    "#add constant to predictor variables\n",
    "x = sm.add_constant(x)\n",
    "\n",
    "#fit linear regression model\n",
    "model = sm.OLS(y, x).fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cfa58c8-0368-40ac-83e5-185ca8fadb63",
   "metadata": {},
   "source": [
    "## Lastly, we can use the following formulas to calculate the SST, SSR, and SSE values of the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "29d9b03b-b123-4d95-901b-900e568a060a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SSE:  331.0748847926267\n",
      "SSR:  917.4751152073769\n",
      "SST:  1248.5500000000036\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "#calculate sse\n",
    "sse = np.sum((model.fittedvalues - df.score)**2)\n",
    "print(\"SSE: \", sse)\n",
    "\n",
    "\n",
    "#calculate ssr\n",
    "ssr = np.sum((model.fittedvalues - df.score.mean())**2)\n",
    "print(\"SSR: \", ssr)\n",
    "\n",
    "#calculate sst\n",
    "sst = ssr + sse\n",
    "print(\"SST: \", sst)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63437e2b-8b83-4d23-8d5d-53cf3dae405e",
   "metadata": {},
   "source": [
    "Information: https://www.statology.org/sst-ssr-sse-in-python/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeec8f21-04bc-4c99-bea3-2ace3640d718",
   "metadata": {},
   "source": [
    "## Q5. In a two-way ANOVA, how would you calculate the main effects and interaction effects using Python?\r\n",
    "\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ae47103-0275-452e-9de7-790bbab77f93",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "335d22dd-105d-483b-afe5-bc36069a1ca5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sum_sq</th>\n",
       "      <th>df</th>\n",
       "      <th>F</th>\n",
       "      <th>PR(&gt;F)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>C(water)</th>\n",
       "      <td>8.533333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>16.0000</td>\n",
       "      <td>0.000527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C(sun)</th>\n",
       "      <td>24.866667</td>\n",
       "      <td>2.0</td>\n",
       "      <td>23.3125</td>\n",
       "      <td>0.000002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C(water):C(sun)</th>\n",
       "      <td>2.466667</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.3125</td>\n",
       "      <td>0.120667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Residual</th>\n",
       "      <td>12.800000</td>\n",
       "      <td>24.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    sum_sq    df        F    PR(>F)\n",
       "C(water)          8.533333   1.0  16.0000  0.000527\n",
       "C(sun)           24.866667   2.0  23.3125  0.000002\n",
       "C(water):C(sun)   2.466667   2.0   2.3125  0.120667\n",
       "Residual         12.800000  24.0      NaN       NaN"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importing libraries \n",
    "import statsmodels.api as sm \n",
    "from statsmodels.formula.api import ols \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "#create data\n",
    "df = pd.DataFrame({'water': np.repeat(['daily', 'weekly'], 15),\n",
    "                   'sun': np.tile(np.repeat(['low', 'med', 'high'], 5), 2),\n",
    "                   'height': [6, 6, 6, 5, 6, 5, 5, 6, 4, 5,\n",
    "                              6, 6, 7, 8, 7, 3, 4, 4, 4, 5,\n",
    "                              4, 4, 4, 4, 4, 5, 6, 6, 7, 8]})\n",
    "\n",
    "\n",
    "#perform two-way ANOVA\n",
    "model = ols('height ~ C(water) + C(sun) + C(water):C(sun)', data=df).fit()\n",
    "sm.stats.anova_lm(model, typ=2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25fcd488-4e0f-441d-a8b3-b936a670f452",
   "metadata": {},
   "source": [
    "We can see the following p-values for each of the factors in the table:\r\n",
    "\r\n",
    "\r\n",
    "water: p-value = .000527,\r\n",
    "  \r\n",
    "Sun: p-value = .0000002\r\n",
    "\r\n",
    "water*sun: p-value = .1206670667"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07f4cffd-4447-4d9b-bfe4-62c75c267859",
   "metadata": {},
   "source": [
    "Since the p-values for water and sun are both less than .05, this means that both factors have a statistically significant effect on plant height.\r\n",
    "\r\n",
    "And since the p-value for the interaction effect (.120667) is not less than .05, this tells us that there is no significant interaction effect between sunlight exposure and watering frequency.\r\n",
    "\r\n",
    "Note: Although the ANOVA results tell us that watering frequency and sunlight exposure have a statistically significant effect on plant height, we would need to perform post-hoc tests to determine exactly how different levels of water and sunlight affect plant height."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb22b8f8-82ee-4cfa-a5d6-2077adf104dd",
   "metadata": {},
   "source": [
    "## Q6. Suppose you conducted a one-way ANOVA and obtained an F-statistic of 5.23 and a p-value of 0.02. What can you conclude about the differences between the groups, and how would you interpret these results?\n",
    "?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a543806-c060-4122-bcbd-18eb50511cf0",
   "metadata": {},
   "source": [
    "F-statistics is larger indicates a greater difference among the group means. It suggests that the variations between the groups are significant.\n",
    "\n",
    "P-Value < Significance Level (e.g., 0.05): If the p-value is less than your chosen significance level (often set at 0.05), it indicates that there are statistically significant differences among the groups. In other words, you have evidence to reject the null hypothesis, which assumes no significant differences."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dec141af-554a-4350-a54a-30bc4376f47e",
   "metadata": {},
   "source": [
    "Information from: https://surveysparrow.com/blog/anova/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53e41c1f-7984-47ed-9558-80a9640b5354",
   "metadata": {},
   "source": [
    "## Q7. In a repeated measures ANOVA, how would you handle missing data, and what are the potential consequences of using different methods to handle missing data?\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97e4031c-fc9e-447d-8e1d-133773200fcb",
   "metadata": {},
   "source": [
    "**LISTWISE DELETION**:\n",
    "\n",
    "By far the most common approach to missing data is to simply omit those cases with missing data and to run our analyses on what remains. Thus if 5 subjects in Group 1 don't show up to be tested, that group is 5 observations short.  Or if 5 individuals have missing scores on one or more variables, we simply omit those individuals from the analysis. This approach is usually called listwise deletion, but it is also known as complete case analysis. \n",
    "\n",
    "Although listwise deletion often results in a substantial decrease in the sample size available for the analysis, it does have important advantages. In particular, under the assumption that data are missing completely at random, it leads to unbiased parameter estimates. Unfortunately, even when the data are MCAR there is a loss in power using this approach, especially if we have to rule out a large number of subjects. And when the data are not MCAR, bias results. (For example when low income individuals are less likely to report their income level, the resulting mean is biased in favor of higher incomes.) The alternative approaches discussed below should be considered as a replacement for listwise deletion, though in some cases we may be better off to \"bite the bullet\" and fall back on listwise deletion.\n",
    "\n",
    "\n",
    "**MULTIPLE IMPUTATION**\n",
    "\n",
    "Just like the old-fashioned imputation methods, Multiple Imputation fills in estimates for the missing data.  But to capture the uncertainty in those estimates, MI estimates the values multiple times. Because it uses an imputation method with error built in, the multiple estimates should be similar, but not identical.\r\n",
    "\r\n",
    "The result is multiple data sets with identical values for all of the non-missing values and slightly different values for the imputed values in each data set. The statistical analysis of interest, such as ANOVA or logistic regression, is performed separately on each data set, and the results are then combined. Because of the variation in the imputed values, there should also be variation in the parameter estimates, leading to appropriate estimates of standard errors and appropriate p-values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54d88f6d-48f4-492f-ad96-118536ef161d",
   "metadata": {},
   "source": [
    "Source: \n",
    "\n",
    "1. https://www.uvm.edu/~statdhtx/StatPages/Missing_Data/Missing-Part-One.html\n",
    "2. https://www.theanalysisfactor.com/missing-data-two-recommended-solutions/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21fd06e8-8faf-4d5f-a65c-1b31d841695a",
   "metadata": {},
   "source": [
    "## Q8. What are some common post-hoc tests used after ANOVA, and when would you use each one? Provide an example of a situation where a post-hoc test might be necessary."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f171e83-c3b6-48a5-a751-e90a9b6a3629",
   "metadata": {},
   "source": [
    "**Tukey's Post Hoc Tests**:\n",
    "\n",
    "Tukey’s Honest Significant Difference (HSD) test is a post hoc test commonly used to assess the significance of differences between pairs of group means. Tukey HSD is often a follow up to one-way ANOVA, when the F-test has revealed the existence of a significant difference between some of the tested groups.\n",
    "\n",
    "**Scheffé's method**:\n",
    "\n",
    "In statistics, Scheffé's method, named after American statistician Henry Scheffé, is a method for adjusting significance levels in a linear regression analysis to account for multiple comparisons. It is particularly useful in analysis of variance (a special case of regression analysis), and in constructing simultaneous confidence bands for regressions involving basis functions.\r\n",
    "\r\n",
    "Scheffé's method is a single-step multiple comparison procedure which applies to the set of estimates of all possible contrasts among the factor level means, not just the pairwise differences considered by the Tukey–Kramer method. It works on similar principles as the Working–Hotelling procedure for estimating mean responses in regression, which applies to the set of all possible factor level\n",
    "\n",
    "**Holm–Bonferroni method**:\n",
    "\n",
    "In statistics, the Holm–Bonferroni method,[1] also called the Holm method or Bonferroni–Holm method, is used to counteract the problem of multiple comparisons. It is intended to control the family-wise error rate (FWER) and offers a simple test uniformly more powerful than the Bonferroni correction. It is named after Sture Holm, who codified the method, and Carlo Emilio Bonferroni.\n",
    "\n",
    "\n",
    "**Example on where the Post Hoc Test is necessary**:\n",
    "\n",
    "A researcher wants to investigate differences in the effectiveness of TikTok, Instagram and Facebook influencers in promoting a nutraceutical brand. Let’s say that, by ANOVA, the null hypothesis (that all three influencer types have similar effectiveness) is rejected. A post-hoc pairwise comparison may then reveal that Instagram influencers have a significantly higher effectiveness in promoting the brand than TikTok and Facebook influencers, while the latter two are similar.s.-8}\r\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd41d9ca-d46a-4681-90cc-c653f63af0ef",
   "metadata": {},
   "source": [
    "## Q9. The following data represent the test scores of two groups of students: Group A: 80, 85, 90, 92, 87, 83; Group B: 75, 78, 82, 79, 81, 84. Conduct an F-test at the 1% significance level to determine if the variances are significantly different.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "af2c12b0-24ad-4094-b8e4-06d12745698d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.stats as stat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1810d9b0-a400-4c4a-9ff4-3bbf9df372a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "group_a = [80, 85, 90, 92, 87, 83]\n",
    "group_b = [75, 78, 82, 79, 81, 84]\n",
    "alpha = 0.99"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5d39b4ac-2b3c-4391-aa00-9ec81bd8f301",
   "metadata": {},
   "outputs": [],
   "source": [
    "variance_a = np.var(group_a)\n",
    "variance_b = np.var(group_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c5822254-f0fd-4563-b162-f8a5ca389b3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "f_value = variance_a/variance_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b40a7000-0afa-4378-9bc1-0925b6de9421",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_a = len(group_a) - 1\n",
    "df_b = len(group_b) - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "106f55c4-6dc4-461d-8890-f0e58c29889e",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_value = stat.f.cdf(f_value, df_a, df_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d81e182b-e858-4af3-b609-163552b3ddb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Degree of freedom 1: 5\n",
      "Degree of freedom 2: 5\n",
      "F-statistic: 1.9442622950819677\n",
      "p-value: 0.7584478225464656\n"
     ]
    }
   ],
   "source": [
    "print('Degree of freedom 1:',df_a)\n",
    "print('Degree of freedom 2:',df_b)\n",
    "print(\"F-statistic:\", f_value)\n",
    "print(\"p-value:\", p_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e8942226-62ec-4592-ac99-b4a919233c12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accept the Null Hypothesis that Var(X) == Var(Y)\n"
     ]
    }
   ],
   "source": [
    "if p_value > alpha:\n",
    "    print(\"Reject the null hypothesis that Var(X) == Var(Y)\")\n",
    "else:\n",
    "    print(\"Accept the Null Hypothesis that Var(X) == Var(Y)\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
