{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a4b5ba6d-f6bd-4977-a398-b83d4417a5bc",
   "metadata": {},
   "source": [
    "### Q1: What are missing values in a dataset? Why is it essential to handle missing values? Name some algorithms that are not affected by missing values.\n",
    "\n",
    "\n",
    "#### <b>Three types of missing values in a dataset:\n",
    "\n",
    "  1. CMAR - Missing Completely at Random\n",
    "  2. MAR -  Missing at Random\n",
    "  3. MNAR - Missing Not at Random\n",
    "\n",
    "\n",
    "#### <b>Why is it essential to handle missing values?\n",
    "\n",
    "Missing data are problematic because, depending on the type, they can sometimes cause sampling bias. \n",
    "\n",
    "In practice, you can often consider $MCAR$ data, $MAR$ data types of missing data ignorable because the missing data don’t systematically differ from your observed values. For these two data types, the likelihood of a data point being missing has nothing to do with the value itself. So it’s unlikely that your missing values are significantly different from your observed values.\n",
    "\n",
    "On the flip side, you have a biased dataset if the missing data systematically differ from your observed data. Data that are MNAR are called non-ignorable for this reason.\n",
    "\n",
    "#### <b><u>Name some algorithms that are not affected by missing values:\n",
    "    \n",
    "    1. CART methodology (Breiman et al. 1984) \n",
    "    2. C5.0 (Quinlan 1993; Kuhn and Johnson 2013)\n",
    "    3. Naive Bayes\n",
    "    \n",
    "Source: http://www.feat.engineering/models-that-are-resistant-to-missing-values.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "806bad00-2e11-4324-9b51-34db1de0f946",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Q2: List down techniques used to handle missing data. Give an example of each with python code.\n",
    "\n",
    "Handling missing values falls generally into two categories. We will look at the most common in each category. The two categories are as follows:\n",
    "  1. Deletion: (i) row deletion that contains missing data, (ii) column deletion which contains missing data(The general rule of thumb for when to perform list-wise deletion is when the number of observations with missing values exceeds the number of observations without missing values.)\n",
    "  2. Imputation: Filling up missing values with Mean, Median and Mode of the columns."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "687af372-25aa-4861-8dd5-901e4e56902c",
   "metadata": {},
   "source": [
    "#### Deletion example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e7c12782-a7b1-42dd-bf6b-6f2d3b8aa6fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>survived</th>\n",
       "      <th>pclass</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>embarked</th>\n",
       "      <th>class</th>\n",
       "      <th>who</th>\n",
       "      <th>adult_male</th>\n",
       "      <th>deck</th>\n",
       "      <th>embark_town</th>\n",
       "      <th>alive</th>\n",
       "      <th>alone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>man</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>no</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C</td>\n",
       "      <td>First</td>\n",
       "      <td>woman</td>\n",
       "      <td>False</td>\n",
       "      <td>C</td>\n",
       "      <td>Cherbourg</td>\n",
       "      <td>yes</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>woman</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>yes</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>S</td>\n",
       "      <td>First</td>\n",
       "      <td>woman</td>\n",
       "      <td>False</td>\n",
       "      <td>C</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>yes</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>man</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>no</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   survived  pclass     sex   age  sibsp  parch     fare embarked  class  \\\n",
       "0         0       3    male  22.0      1      0   7.2500        S  Third   \n",
       "1         1       1  female  38.0      1      0  71.2833        C  First   \n",
       "2         1       3  female  26.0      0      0   7.9250        S  Third   \n",
       "3         1       1  female  35.0      1      0  53.1000        S  First   \n",
       "4         0       3    male  35.0      0      0   8.0500        S  Third   \n",
       "\n",
       "     who  adult_male deck  embark_town alive  alone  \n",
       "0    man        True  NaN  Southampton    no  False  \n",
       "1  woman       False    C    Cherbourg   yes  False  \n",
       "2  woman       False  NaN  Southampton   yes   True  \n",
       "3  woman       False    C  Southampton   yes  False  \n",
       "4    man        True  NaN  Southampton    no   True  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "# bringing dataset with NUll VALUES.\n",
    "\n",
    "df = sns.load_dataset('titanic')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "92ce0d3d-dd36-4268-a914-d378843c0f17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "survived         0\n",
       "pclass           0\n",
       "sex              0\n",
       "age            177\n",
       "sibsp            0\n",
       "parch            0\n",
       "fare             0\n",
       "embarked         2\n",
       "class            0\n",
       "who              0\n",
       "adult_male       0\n",
       "deck           688\n",
       "embark_town      2\n",
       "alive            0\n",
       "alone            0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Checking missing values, column wise\n",
    "\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4e575aa-73d4-4ef3-86db-cec5458d4f83",
   "metadata": {},
   "source": [
    "#### column wise deletion\n",
    "\n",
    "Above, you can see 'deck' feature or column has most of its value as null. So, in this you can delete the 'deck' columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "72aee25f-6def-49c8-8392-4cd4b2b0b5eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>survived</th>\n",
       "      <th>pclass</th>\n",
       "      <th>sex</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>class</th>\n",
       "      <th>who</th>\n",
       "      <th>adult_male</th>\n",
       "      <th>alive</th>\n",
       "      <th>alone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>Third</td>\n",
       "      <td>man</td>\n",
       "      <td>True</td>\n",
       "      <td>no</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>First</td>\n",
       "      <td>woman</td>\n",
       "      <td>False</td>\n",
       "      <td>yes</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>Third</td>\n",
       "      <td>woman</td>\n",
       "      <td>False</td>\n",
       "      <td>yes</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>First</td>\n",
       "      <td>woman</td>\n",
       "      <td>False</td>\n",
       "      <td>yes</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>Third</td>\n",
       "      <td>man</td>\n",
       "      <td>True</td>\n",
       "      <td>no</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>Second</td>\n",
       "      <td>man</td>\n",
       "      <td>True</td>\n",
       "      <td>no</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>First</td>\n",
       "      <td>woman</td>\n",
       "      <td>False</td>\n",
       "      <td>yes</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>23.4500</td>\n",
       "      <td>Third</td>\n",
       "      <td>woman</td>\n",
       "      <td>False</td>\n",
       "      <td>no</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>First</td>\n",
       "      <td>man</td>\n",
       "      <td>True</td>\n",
       "      <td>yes</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.7500</td>\n",
       "      <td>Third</td>\n",
       "      <td>man</td>\n",
       "      <td>True</td>\n",
       "      <td>no</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>891 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     survived  pclass     sex  sibsp  parch     fare   class    who  \\\n",
       "0           0       3    male      1      0   7.2500   Third    man   \n",
       "1           1       1  female      1      0  71.2833   First  woman   \n",
       "2           1       3  female      0      0   7.9250   Third  woman   \n",
       "3           1       1  female      1      0  53.1000   First  woman   \n",
       "4           0       3    male      0      0   8.0500   Third    man   \n",
       "..        ...     ...     ...    ...    ...      ...     ...    ...   \n",
       "886         0       2    male      0      0  13.0000  Second    man   \n",
       "887         1       1  female      0      0  30.0000   First  woman   \n",
       "888         0       3  female      1      2  23.4500   Third  woman   \n",
       "889         1       1    male      0      0  30.0000   First    man   \n",
       "890         0       3    male      0      0   7.7500   Third    man   \n",
       "\n",
       "     adult_male alive  alone  \n",
       "0          True    no  False  \n",
       "1         False   yes  False  \n",
       "2         False   yes   True  \n",
       "3         False   yes  False  \n",
       "4          True    no   True  \n",
       "..          ...   ...    ...  \n",
       "886        True    no   True  \n",
       "887       False   yes   True  \n",
       "888       False    no  False  \n",
       "889        True   yes   True  \n",
       "890        True    no   True  \n",
       "\n",
       "[891 rows x 11 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# In the below code, all the column which have null values will be deleted. So, in this case, 'age' & 'deck' both \n",
    "# column will be deleted.\n",
    "\n",
    "# you have mention inplace = True in order to make the change permanent. \n",
    "\n",
    "df.dropna(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9ec4d9e0-84ec-46a7-8f41-bbc26849cf3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# as we wanted to drop only 'deck' column, then we can use the below code:\n",
    "\n",
    "df.drop(columns=['deck'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ab40bbe9-973c-407b-87a3-7730cc1ff4da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['survived', 'pclass', 'sex', 'age', 'sibsp', 'parch', 'fare',\n",
       "       'embarked', 'class', 'who', 'adult_male', 'embark_town', 'alive',\n",
       "       'alone'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# in the below list of columns, you will not able to find the 'deck' column\n",
    "\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "527f94bf-c634-451d-8b0b-ca9dd4007e40",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Row Deletion with Null Value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4d6fa2b2-6d7f-428e-b63e-e23945332653",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>survived</th>\n",
       "      <th>pclass</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>embarked</th>\n",
       "      <th>class</th>\n",
       "      <th>who</th>\n",
       "      <th>adult_male</th>\n",
       "      <th>embark_town</th>\n",
       "      <th>alive</th>\n",
       "      <th>alone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>man</td>\n",
       "      <td>True</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>no</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C</td>\n",
       "      <td>First</td>\n",
       "      <td>woman</td>\n",
       "      <td>False</td>\n",
       "      <td>Cherbourg</td>\n",
       "      <td>yes</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>woman</td>\n",
       "      <td>False</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>yes</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>S</td>\n",
       "      <td>First</td>\n",
       "      <td>woman</td>\n",
       "      <td>False</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>yes</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>man</td>\n",
       "      <td>True</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>no</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>885</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>39.0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>29.1250</td>\n",
       "      <td>Q</td>\n",
       "      <td>Third</td>\n",
       "      <td>woman</td>\n",
       "      <td>False</td>\n",
       "      <td>Queenstown</td>\n",
       "      <td>no</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>male</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>S</td>\n",
       "      <td>Second</td>\n",
       "      <td>man</td>\n",
       "      <td>True</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>no</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>S</td>\n",
       "      <td>First</td>\n",
       "      <td>woman</td>\n",
       "      <td>False</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>yes</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>C</td>\n",
       "      <td>First</td>\n",
       "      <td>man</td>\n",
       "      <td>True</td>\n",
       "      <td>Cherbourg</td>\n",
       "      <td>yes</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.7500</td>\n",
       "      <td>Q</td>\n",
       "      <td>Third</td>\n",
       "      <td>man</td>\n",
       "      <td>True</td>\n",
       "      <td>Queenstown</td>\n",
       "      <td>no</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>712 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     survived  pclass     sex   age  sibsp  parch     fare embarked   class  \\\n",
       "0           0       3    male  22.0      1      0   7.2500        S   Third   \n",
       "1           1       1  female  38.0      1      0  71.2833        C   First   \n",
       "2           1       3  female  26.0      0      0   7.9250        S   Third   \n",
       "3           1       1  female  35.0      1      0  53.1000        S   First   \n",
       "4           0       3    male  35.0      0      0   8.0500        S   Third   \n",
       "..        ...     ...     ...   ...    ...    ...      ...      ...     ...   \n",
       "885         0       3  female  39.0      0      5  29.1250        Q   Third   \n",
       "886         0       2    male  27.0      0      0  13.0000        S  Second   \n",
       "887         1       1  female  19.0      0      0  30.0000        S   First   \n",
       "889         1       1    male  26.0      0      0  30.0000        C   First   \n",
       "890         0       3    male  32.0      0      0   7.7500        Q   Third   \n",
       "\n",
       "       who  adult_male  embark_town alive  alone  \n",
       "0      man        True  Southampton    no  False  \n",
       "1    woman       False    Cherbourg   yes  False  \n",
       "2    woman       False  Southampton   yes   True  \n",
       "3    woman       False  Southampton   yes  False  \n",
       "4      man        True  Southampton    no   True  \n",
       "..     ...         ...          ...   ...    ...  \n",
       "885  woman       False   Queenstown    no  False  \n",
       "886    man        True  Southampton    no   True  \n",
       "887  woman       False  Southampton   yes   True  \n",
       "889    man        True    Cherbourg   yes   True  \n",
       "890    man        True   Queenstown    no   True  \n",
       "\n",
       "[712 rows x 14 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this will drop all the rows with null value in it. This is not desirable as we lose a lot of data portions.\n",
    "\n",
    "df.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "609cad7a-bcd0-40e6-8bba-f779c8f8f492",
   "metadata": {},
   "source": [
    "#### Imputation of Missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ff04f82b-5147-4659-be76-9ab620b3fd60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>age_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22.0</td>\n",
       "      <td>22.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38.0</td>\n",
       "      <td>38.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>26.0</td>\n",
       "      <td>26.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>35.0</td>\n",
       "      <td>35.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>35.0</td>\n",
       "      <td>35.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>27.0</td>\n",
       "      <td>27.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>19.0</td>\n",
       "      <td>19.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>NaN</td>\n",
       "      <td>29.699118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>26.0</td>\n",
       "      <td>26.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>32.0</td>\n",
       "      <td>32.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>891 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      age   age_mean\n",
       "0    22.0  22.000000\n",
       "1    38.0  38.000000\n",
       "2    26.0  26.000000\n",
       "3    35.0  35.000000\n",
       "4    35.0  35.000000\n",
       "..    ...        ...\n",
       "886  27.0  27.000000\n",
       "887  19.0  19.000000\n",
       "888   NaN  29.699118\n",
       "889  26.0  26.000000\n",
       "890  32.0  32.000000\n",
       "\n",
       "[891 rows x 2 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mean Imputation:\n",
    "\n",
    "'''\n",
    "\n",
    "1. df['age'].mean() -- calculate mean value of the values of 'age' column\n",
    "2. df['age'].fillna(df['age'].mean()) - will fill the missing value with the calculated mean value\n",
    "3. df['age_mean'] = df['age'].fillna(df['age'].mean()) - will create 'age_imputed' new column with the replaced missing \n",
    "value by the mean value. \n",
    "\n",
    "'''\n",
    "\n",
    "df['age_mean'] = df['age'].fillna(df['age'].mean()) \n",
    "df[['age', 'age_mean']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "55efd96f-4ef9-4e97-ab16-8a285e712f07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>age_median</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22.0</td>\n",
       "      <td>22.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38.0</td>\n",
       "      <td>38.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>26.0</td>\n",
       "      <td>26.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>35.0</td>\n",
       "      <td>35.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>35.0</td>\n",
       "      <td>35.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>27.0</td>\n",
       "      <td>27.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>19.0</td>\n",
       "      <td>19.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>NaN</td>\n",
       "      <td>28.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>26.0</td>\n",
       "      <td>26.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>32.0</td>\n",
       "      <td>32.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>891 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      age  age_median\n",
       "0    22.0        22.0\n",
       "1    38.0        38.0\n",
       "2    26.0        26.0\n",
       "3    35.0        35.0\n",
       "4    35.0        35.0\n",
       "..    ...         ...\n",
       "886  27.0        27.0\n",
       "887  19.0        19.0\n",
       "888   NaN        28.0\n",
       "889  26.0        26.0\n",
       "890  32.0        32.0\n",
       "\n",
       "[891 rows x 2 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Median Imputation  -- if we have outliers in the dataset\n",
    "\n",
    "'''\n",
    "\n",
    "1. df['age'].median() -- calculate mean value of the values of 'age' column\n",
    "2. df['age'].fillna(df['age'].median()) - will fill the missing value with the calculated mean value\n",
    "3. df['age_median'] = df['age'].fillna(df['age'].median()) - will create 'age_imputed' new column with the replaced missing \n",
    "value by the mean value. \n",
    "\n",
    "'''\n",
    "\n",
    "df['age_median'] = df['age'].fillna(df['age'].median()) \n",
    "df[['age', 'age_median']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "996f548b-0b2f-427b-9b57-439d6237c3cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculated Mode:  S\n"
     ]
    }
   ],
   "source": [
    "# Mode Imputation - done on categorical dataset\n",
    "\n",
    "'''\n",
    "1. df['embarked'].notna() - all the non-null values as True and Null values as false\n",
    "2. df[df['embarked'].notna()] - total dataframe with only those non-null values\n",
    "3. df[df['embarked'].notna()]['embarked'] - embarked column with non-null values\n",
    "4. df[df['embarked'].notna()]['embarked'].mode() - returns a series with mode values of the non-null values of embarked column\n",
    "5. df[df['embarked'].notna()]['embarked'].mode()[0] - retunrs the mode value\n",
    "\n",
    "'''\n",
    "\n",
    "mode_value = df[df['embarked'].notna()]['embarked'].mode()[0]\n",
    "print(\"Calculated Mode: \", mode_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "69e33e26-b487-4a7e-8c25-85d71989299d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filling up all the missing values of embarked column with mode value and creating a new column 'embarked_mode' with it.\n",
    "\n",
    "df['embarked_mode'] = df['embarked'].fillna(mode_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c5775e27-dbdb-4489-b776-efede19ae8b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "S    644\n",
       "C    168\n",
       "Q     77\n",
       "Name: embarked, dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['embarked'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "337b39b1-bb97-4549-8997-556564691941",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "S    646\n",
       "C    168\n",
       "Q     77\n",
       "Name: embarked_mode, dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# in the new colummn, u will find two 's' value increased. cause two missing value has been replcaed with mode value which is 's'\n",
    "# in this case.\n",
    "\n",
    "df['embarked_mode'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d72ed5d6-f153-40dc-bbca-7d444f9344df",
   "metadata": {},
   "source": [
    "### Q3: Explain the imbalanced data. What will happen if imbalanced data is not handled?\n",
    "\n",
    "\n",
    "#### <b><u>Imbalanced Data:\n",
    "Imbalanced data refers to those types of datasets where the target class has an uneven distribution of observations, i.e one class label has a very high number of observations and the other has a very low number of observations. \n",
    "\n",
    "Classes that make up a large proportion of the data set are called majority classes. Those that make up a smaller proportion are minority classes.\n",
    "    \n",
    "#### <b><u>What will happen if imbalanced data is not handled?\n",
    "\n",
    "If the dataset is biased towards one class, an algorithm trained on the same data will be biased towards the same class.\n",
    "\n",
    "The model learns more from biased examples as opposed to the examples in the minority class. One might end up with a scenario where a model assumes that any data you feed it belongs to the majority class.\n",
    "\n",
    "This, as a result, makes a model seem naïve in its predictions, regardless of achieving high accuracy scores."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30efcdbe-d39d-4e04-bfac-1f322dd6f522",
   "metadata": {},
   "source": [
    "### Q4: What are Up-sampling and Down-sampling? Explain with an example when up-sampling and downsampling are required.\n",
    "\n",
    "\n",
    "#### <b><u>Oversampling or Up-Sampling:\n",
    "\n",
    "Oversampling is a technique to alter unequal classes of data to create balanced datasets. This technique attempts to increment the size of rare samples to create a balance when the data is insufficient.\n",
    "\n",
    "<b><u>Example:\n",
    "    \n",
    "For example, let’s have a classification problem with two classes and 100K data points. 20K data points are of the positive class, 80K for the negative class. The positive class, which is the minority class, would need to be oversampled.\n",
    "\n",
    "To do this, we take the 20K data points and replicate them four times to produce 80K. This yields an equal number of examples for both positive and negative classes. The size of the dataset would increase to 160K as a result.\n",
    "    \n",
    "    \n",
    "#### <b><u> Undersampling or Down-Sampling:\n",
    "\n",
    "When there exists a class that is in abundance in an imbalanced dataset, undersampling aims to reduce the size of the abundant class to balance the dataset.\n",
    "    \n",
    "<b><u>Example:\n",
    "\n",
    "Using a similar context to the oversampling example, we have a classification problem with two classes and 100K data points. 20K data points are of the positive class, 80K for the negative class. We would need to undersample the majority class.\n",
    "\n",
    "This would involve choosing 20K data points randomly from the 80K available. We then have 20K positive and 20K negative data points, bringing the total dataset size to 40K data points.\n",
    "    \n",
    "\n",
    "Source: https://www.section.io/engineering-education/imbalanced-data-in-ml/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e42fb14e-20d0-48d9-bfc0-c50c1781db30",
   "metadata": {},
   "source": [
    "### Q5: What is data Augmentation? Explain SMOTE.\n",
    "\n",
    "#### <b><u> Data Augmentation: \n",
    "    \n",
    "Data augmentation is a technique of artificially increasing the training set by creating modified copies of a dataset using existing data. It includes making minor changes to the dataset or using deep learning to generate new data points.  \n",
    "    \n",
    "#### <b><u>SMOTE (Synthetic Minority Oversampling Technique) – Oversampling\n",
    "\n",
    "SMOTE (Synthetic Minority Oversampling Technique) is one of the most commonly used oversampling methods to solve the imbalance problem.\n",
    "    \n",
    "It aims to balance class distribution by randomly increasing minority class examples by replicating them.\n",
    "    \n",
    "SMOTE synthesises new minority instances between existing minority instances. It generates the virtual training records by linear interpolation for the minority class. These synthetic training records are generated by randomly selecting one or more of the k-nearest neighbors for each example in the minority class. After the oversampling process, the data is reconstructed and several classification models can be applied for the processed data.\n",
    "    \n",
    "<b><u>More Deep Insights of how SMOTE Algorithm work:\n",
    "    \n",
    "* Step 1: Setting the minority class set A, for each $x \\in A$, the k-nearest neighbors of x are obtained by calculating the Euclidean distance between x and every other sample in set A.\n",
    "* Step 2: The sampling rate N is set according to the imbalanced proportion. For each $x \\in A$, N examples (i.e x1, x2, …xn) are randomly selected from its k-nearest neighbors, and they construct the set $A_1$ .\n",
    "* Step 3: For each example $x_k \\in A_1$ (k=1, 2, 3…N), the following formula is used to generate a new example:\n",
    "          $x' = x + rand(0, 1) * \\mid x - x_k \\mid$\n",
    "    in which rand(0, 1) represents the random number between 0 and 1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3768da2-82a5-4a3b-b535-a0f8732a13b9",
   "metadata": {},
   "source": [
    "### Q6: What are outliers in a dataset? Why is it essential to handle outliers?\n",
    "\n",
    "#### <b><u>Outlier\n",
    "    \n",
    "In simple terms, an outlier is an extremely high or extremely low data point relative to the nearest data point and the rest of the neighboring co-existing values in a data graph or dataset you're working with.\n",
    "\n",
    "Outliers are extreme values that stand out greatly from the overall pattern of values in a dataset or graph.\n",
    "    \n",
    "#### <b><u>Why is it essential to handle outliers?\n",
    "    \n",
    "Effect of outliers on a data set Outliers have a huge impact on the result of data analysis and various statistical measures. It is important to handle outliers so that we can reduce the below effects on the dataset because of their presence: \n",
    "\n",
    "* If the outliers are non-randomly distributed, they can decrease normality.\n",
    "* It increases the error variance and reduces the power of statistical tests.\n",
    "* They can cause bias and/or influence estimates.\n",
    "* They can also impact the basic assumption of regression as well as other statistical models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adb65bc4-85cd-4dbd-a062-892f0b338983",
   "metadata": {},
   "source": [
    "#### Q7: You are working on a project that requires analyzing customer data. However, you notice that some of the data is missing. What are some techniques you can use to handle the missing data in your analysis?\n",
    "\n",
    "\n",
    "* We can use the Deletion Method like: row deletion as we have some data that are missing\n",
    "* We can use Imputation Method like, mean imputation, median imputation & mode imputation to replace the missing values with mean, median and mode of the non-null feature values.\n",
    "\n",
    "* it is important to choose right Imputation method and it depends upon what type of missing data we are having in the dataset.\n",
    "\n",
    "<table>\n",
    "    <th>\n",
    "        <tr>\n",
    "            <td><b>Type of missing data</b></td>\n",
    "            <td><b>Imputation method</b></td>\n",
    "        </tr>\n",
    "    </th>\n",
    "    <td>\n",
    "        <tr>\n",
    "            <td>Missing Completely At Random</td>\n",
    "            <td>Mean, Median, Mode, or any other imputation method</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>Missing At Random</td>\n",
    "            <td>Multiple imputation, Regression imputation</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>Missing Not At Random</td>\n",
    "            <td>Pattern Substitution, Maximum Likelihood estimation</td>\n",
    "        </tr>\n",
    "    </td>\n",
    "</table>\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "174281fe-fe16-4d18-aea2-dc6fb0f06390",
   "metadata": {},
   "source": [
    "### Q8: You are working with a large dataset and find that a small percentage of the data is missing. What are some strategies you can use to determine if the missing data is missing at random or if there is a pattern to the missing data?\n",
    "\n",
    "#### <b><u>Strategies to determine the type of missing data:\n",
    "    \n",
    "\n",
    "1. <b>The Missing Data is MCAR(Missing Completely at Random)</b>: This happens if all the variables and observations have the same probability of being missing. \n",
    "\n",
    "2. <b>The Missing Data is MAR(Missing at Random)</b>: This happens when the probability of the value being missing is related to the value of the variable or other variables in the dataset. This means that not all the observations and variables have the same chance of being missing.\n",
    "\n",
    "3. <b>Missing Data in MNAR(Missing Not at Random)</b>: MNAR is considered to be the most difficult scenario among the three types of missing data. It is applied when neither MAR nor MCAR apply. In this situation, the probability of being missing is completely different for different values of the same variable, and these reasons can be unknown to us. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f91814f4-b541-4bb6-b0f2-87c72b6cdb9b",
   "metadata": {},
   "source": [
    "#### Q9: Suppose you are working on a medical diagnosis project and find that the majority of patients in the dataset do not have the condition of interest, while a small percentage do. What are some strategies you can use to evaluate the performance of your machine learning model on this imbalanced dataset?\n",
    "\n",
    "\n",
    "\n",
    "The most common metrics to use for imbalanced datasets are:\n",
    "\n",
    "* F1 score\n",
    "* Precision\n",
    "* Recall\n",
    "* AUC score (AUC ROC)\n",
    "* Average precision score (AP)\n",
    "* G-Mean\n",
    "\n",
    "It is good practice to track multiple metrics when developing a machine learning model as each highlights different aspects of model performance.\n",
    "\n",
    "\n",
    "For More Details: https://www.kaggle.com/code/marcinrutecki/best-techniques-and-metrics-for-imbalanced-dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0b0bc6f-bb0b-4f1a-a2c1-5006142e1c51",
   "metadata": {},
   "source": [
    "### Q10: When attempting to estimate customer satisfaction for a project, you discover that the dataset is unbalanced, with the bulk of customers reporting being satisfied. What methods can you employ to balance the dataset and down-sample the majority class?\n",
    "\n",
    "\n",
    "Some of the more widely used and implemented undersampling methods includes which can be used to down-sample the majority class are:\n",
    "\n",
    "    Random Undersampling\n",
    "    Condensed Nearest Neighbor Rule (CNN)\n",
    "    Near Miss Undersampling\n",
    "    Tomek Links Undersampling\n",
    "    Edited Nearest Neighbors Rule (ENN)\n",
    "    One-Sided Selection (OSS)\n",
    "    Neighborhood Cleaning Rule (NCR)\n",
    "\n",
    "\n",
    "For more information: https://machinelearningmastery.com/data-sampling-methods-for-imbalanced-classification/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00459a92-7669-4ad3-bee8-888bec2484a8",
   "metadata": {},
   "source": [
    "### Q11: You discover that the dataset is unbalanced with a low percentage of occurrences while working on a project that requires you to estimate the occurrence of a rare event. What methods can you employ to balance the dataset and up-sample the minority class?\n",
    "\n",
    "\n",
    "Some of the more widely used and implemented oversampling methods include which can be used on this case:\n",
    "\n",
    "    Random Oversampling\n",
    "    Synthetic Minority Oversampling Technique (SMOTE)\n",
    "    Borderline-SMOTE\n",
    "    Borderline Oversampling with SVM\n",
    "    Adaptive Synthetic Sampling (ADASYN)\n",
    "\n",
    "\n",
    "* For more information: https://machinelearningmastery.com/data-sampling-methods-for-imbalanced-classification/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
